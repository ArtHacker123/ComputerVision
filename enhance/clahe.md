# AHE/CLAHE

### 问题

对比增强是一个很经典的问题，我们在用相机拍摄照片的过程中很容易把物体拍得亮或者暗，带来的问题就是暗部细节或者亮部细节不明显，于是乎，如何均匀地把细节展示出来就成了一个问题。

### Histogram Equalization/直方图均衡

直方图均衡是一个很简单的方法，他的思想是通过CDF（累积概率分布）把图像的均衡拉伸。举例来说：

```python
def example():
  a = [3, 4, 5, 5, 5, 5, 6, 7, 7, 7]
  pdf = [0] * 10
  for i in range(0, 10):
    pdf[i] = len(a[a == i])
  cdf = pdf.cumsum()
  cdf -= 1
  # index=[ 0,  1,  2, 3, 4, 5, 6, 7, 8, 9]
  # cdf = [-1, -1, -1, 0, 1, 5, 6, 9, 9, 9]
  # mapping each cdf to each number
```

从上面的代码可以看出，通过CDF的重新映射，3被映射到了0，而7被映射到了9，这样原本存在于[3，7]之间的数被扩展到了[0,9]，图像的动态性得到了很大地提高。

### Adaptive Histogram Equalization

上面的方法存在一些问题，那就是当一张图片服从一个比较均匀的光照，那么这样用全局的算法问题不大，但是经常遇到的问题是，一张图亮的地方很亮，而暗的地方很暗，做完均衡化后，要么暗处没法看，要么亮处没法看。

所以人们自然而然地想到了局部均衡化的方法。这个方法也很简单，就是把一张图切成一个个的小格子，在每一个小格子里面做均衡化，问题就解决了。

这样做带来的好处是对光照会更鲁棒一点，毕竟一般来说亮的地方附近也会亮，考虑这一个小部分的信息总不会差得太远，但是直接这么搞也会产生一些问题，那就是会产生所谓的artifact，就是说对于一个正好处于亮暗交界的小块，和一个处于正常光源的小块，它们的环境不一样，做均衡化的结果也会大不一样，那它的结果可能会差距很大，输出的结果会产生一些突变，这会和人所感知的平缓变化产生差异。

基于这个问题，算法采用了双线性差值的方法，也就是说对于任意一个小块，会考虑附近几个小块的信息，这样一做平均，数据的方差肯定会下降，这样看上去就平滑了好多了。

### Contrast Limit Adaptive Histogram Equalization

这个方法可以说是上面那个方法的正则版，对于机器学习比较熟悉的童鞋都知道，正则项保证了模型不会太过激进，里面的参数的数值会偏向于保守，而这个算法的思路也是这样。

它对于那些PDF比较大的像素点会进行强制截断，然后将多出来的数值分给其他的像素值，这样图像会看着更均衡一些。这个算法现在已经成为OpenCV 3.0中的一员，详细的内容可以查看源代码。

源代码的思路是对于每个块，计算它的直方图结果，在复原时直接从附近块的直方图查找结果进行双线性插值即可。

### Reference

[OpenCV Source Code](https://github.com/Itseez/opencv/blob/debe99f1a4cc0ea859b91996613934e361b544b6/modules/imgproc/src/clahe.cpp)
